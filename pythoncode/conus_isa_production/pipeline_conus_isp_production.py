"""
    Pipeline for generating the ISP for the CONUS region using the trained U-Net model
    Major steps:
    (1) Prepare predictor variables: extracting the COLD features and topography information
    (2) U-Net prediction

    In CONUS, the total tile number is 427.

    Running time for one tile and one year:
    (1) Predictor variable preparation: ~1
    (2) U-Net prediction: 5 minutes

    Memory usage: 30 GBs per job for recommendation

    Outputs:
    (1) IS mask generated by U-Net classifier
    (2) IS percentage generated by U-Net regression
    (3) Masked IS percentage using IS mask, i.e., the final ISP product
    
    Using 120 cores, the running time for 1 year all CONUS is around 2.5 hours
    Recommend to use 200 cores for the whole CONUS ISP production, for two reasons
    (1) Memory usage is around 30 GBs per job, not enough memory in HPC, might take longer time to wait for the job
    (2) The I/O is intensive. 200 cores might be the optimal number for the I/O performance
    
    Using 200 cores for 7 years running, it takes 8-13 hours, depending on the complexity of each tile and year 
"""


import os
from os.path import join
import numpy as np
import sys
import pandas as pd
import yaml
import scipy.io as scio
from osgeo import gdalconst, gdal_array
from datetime import datetime
import click
import logging
import torch

pwd = os.getcwd()
rootpath_project = os.path.abspath(os.path.join(pwd, '../..'))
path_pythoncode = join(rootpath_project, 'pythoncode')
sys.path.append(path_pythoncode)

from pythoncode.util_function.datetime_datenum_convert import datetime_to_datenum_matlabversion
from util_function.mat_to_dataframe import mat_to_dataframe

from pythoncode.conus_isa_production.surface_reflectance_calculate_annual_bytile import (mask_flag_generate,
                                                                                         get_annual_overall_reflectance)

from pythoncode.model_training.unet_prediction import (unet_model_load,
                                                       mosaic_prediction,
                                                       predict_isp_output)

from pythoncode.model_training.utils_deep_learning import (predictor_normalize,
                                                           read_topography_data,
                                                           topography_normalize,
                                                           get_proj_info,
                                                           add_pyramids_color_in_nlcd_isp_tif, )

from pythoncode.conus_isa_production.utils_get_conus_tile_name import get_conus_tile_name



def get_running_task(list_year, list_tile_name):
    """
    get the running task

    :param list_year:
    :param list_tile_name:
    :return:
    """

    df_running_task = pd.DataFrame(columns=['tile_name', 'year'], index=np.arange(0, len(list_tile_name) * len(list_year)))
    i_task = 0
    for year in list_year:
        for tile_name in list_tile_name:
            df_running_task.loc[i_task, 'tile_name'] = tile_name
            df_running_task.loc[i_task, 'year'] = year
            i_task += 1

    return df_running_task


def define_logger(filename_logger):
    """
        define the logger for CONUS isp calculation
    """

    logger_isp_cal = logging.getLogger('conus_isp_production')
    logger_isp_cal.setLevel(logging.INFO)

    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    file_handler = logging.FileHandler(filename_logger)
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(formatter)
    logger_isp_cal.addHandler(file_handler)

    logger_isp_cal.addHandler(file_handler)

    return logger_isp_cal


def get_cold_features_tile_year(path_cold,
                                tile_name,
                                list_year_for_extraction,
                                nan_fill=0,
                                rows_running=5000,
                                logger=None):
    """
        get the surface reflectance image from the COLD rec_cg file
    Args:
        path_cold: the path of the COLD rec_cg file
        tile_name: e.g., h026v006
        list_year_for_extraction: the list of years for extraction, such as np.arange(1985, 2022)
        nan_fill: the value used to fill the nan value when the final image contains nan value, default is 0
        rows_running: the total rows in the COLD rec_cg file, default is 5000
        logger: the logger for the extraction process
    """

    assert logger is not None, 'logger is not defined'

    path_record_change = join(path_cold, tile_name, 'TSFitLine')

    NRows, NCols = 5000, 5000
    NBands = 7

    # define the output image to store the extracted variables
    img_sr_change = np.zeros((len(list_year_for_extraction), NBands, NRows, NCols), dtype=np.float32) + 9999.0

    img_c1 = np.zeros((len(list_year_for_extraction), NBands, NRows, NCols), dtype=np.float32) + 9999.0
    img_rmse = np.zeros((len(list_year_for_extraction), NBands, NRows, NCols), dtype=np.float32) + 9999.0

    img_a1 = np.zeros((len(list_year_for_extraction), NBands, NRows, NCols), dtype=np.float32) + 9999.0
    img_b1 = np.zeros((len(list_year_for_extraction), NBands, NRows, NCols), dtype=np.float32) + 9999.0

    for row_id in range(0, rows_running):

        if row_id % 1000 == 0:
            logger.info('tile {} row {:04d} extraction'.format(tile_name, row_id))

        file_name_ydata_training = join(path_record_change, 'record_change_r0{:04d}.mat'.format(row_id + 1))    # type: ignore

        data = scio.loadmat(file_name_ydata_training, verify_compressed_data_integrity=False)   # type: ignore
        mat_rec_cg = data['rec_cg']
        df_matfile = mat_to_dataframe(mat_rec_cg)

        if len(df_matfile) == 1:
            logger.info('tile {} row {:04d} no data'.format(tile_name, row_id))
            continue

        # get the central overall reflectance
        array_t_start = np.array([line[0][0] for line in df_matfile['t_start']])
        array_t_end = np.array([line[0][0] for line in df_matfile['t_end']])

        array_pos = np.array([line[0][0] for line in df_matfile['pos']])

        # get the RMSE
        array_rmse = np.array([line for line in df_matfile['rmse']])[:, :, 0]

        array_c1 = np.array([line[1, :] for line in df_matfile['coefs']])

        array_a1 = np.array([line[2, :] for line in df_matfile['coefs']])
        array_b1 = np.array([line[3, :] for line in df_matfile['coefs']])

        for i_year in range(0, len(list_year_for_extraction)):
            year = list_year_for_extraction[i_year]

            datetime_target = datetime(year=year, month=7, day=1)
            datenum_target = datetime_to_datenum_matlabversion(datetime_target)

            # generate the mask for matching the COLD parameters with the target date
            mask_same_period, series_pos = mask_flag_generate(datenum_target, datetime_target, array_t_start, array_t_end, array_pos, row_id)

            array_annual_overall_sr = get_annual_overall_reflectance(df_matfile, datenum_target)

            img_sr_change[i_year, :, row_id, series_pos] = array_annual_overall_sr[mask_same_period, :]

            img_c1[i_year, :, row_id, series_pos] = array_c1[mask_same_period, :]
            img_rmse[i_year, :, row_id, series_pos] = array_rmse[mask_same_period, :]

            img_a1[i_year, :, row_id, series_pos] = array_a1[mask_same_period, :]
            img_b1[i_year, :, row_id, series_pos] = array_b1[mask_same_period, :]

    img_sr_change[img_sr_change == 9999.0] = nan_fill

    img_c1[img_c1 == 9999.0] = nan_fill
    img_rmse[img_rmse == 9999.0] = nan_fill

    img_a1[img_a1 == 9999.0] = nan_fill
    img_b1[img_b1 == 9999.0] = nan_fill

    img_sr_change = np.squeeze(img_sr_change)
    img_c1 = np.squeeze(img_c1)
    img_rmse = np.squeeze(img_rmse)
    img_a1 = np.squeeze(img_a1)
    img_b1 = np.squeeze(img_b1)

    return img_sr_change, img_rmse, img_c1, img_a1, img_b1


def pipeline_conus_predictor_preparation(path_cold_reccg, tile_name, year, norm_boundary_folder, logger, nan_fill=0, rows_running=5000):
    """
    pipeline to prepare the predictor variables for the CONUS ISP prediction, including two parts

    (1) get COLD features from the COLD rec_cg file
    (2) get topography features from the DEM, slope, and aspect

    :param path_cold_reccg:
    :param tile_name:
    :param year:
    :param norm_boundary_folder:
    :param logger:
    :param nan_fill:
    :param rows_running:

    :return:
    """

    list_year_extraction = np.arange(year, year + 1)

    (img_sr_change, img_rmse,
     img_c1, img_a1, img_b1) = get_cold_features_tile_year(path_cold=path_cold_reccg,
                                                           tile_name=tile_name,
                                                           list_year_for_extraction=list_year_extraction,
                                                           nan_fill=nan_fill,
                                                           rows_running=rows_running,
                                                           logger=logger)

    img_cold_coefficients = np.concatenate([img_sr_change, img_a1, img_b1, img_c1, img_rmse])

    # normalize the COLD variables
    img_cold_coefficients = predictor_normalize(img_cold_coefficients, norm_boundary_folder=norm_boundary_folder)

    # read the topography data
    img_dem, img_slope, img_aspect = read_topography_data(tile_name)
    # normalize the topography data
    img_dem, img_slope, img_aspect = topography_normalize(img_dem, img_slope, img_aspect,
                                                          norm_boundary_folder=norm_boundary_folder)

    predictor = np.concatenate((img_cold_coefficients, img_dem, img_slope, img_aspect), axis=0)

    return predictor


def pipeline_conus_unet_prediction(tile_name,
                                   year,
                                   predictor,
                                   output_path,
                                   task_type_flag,
                                   training_version,
                                   epoch,
                                   logger,
                                   filename_prefix='unet_classifier',
                                   rootpath_project_folder=None,
                                   ):

    """
    pipeline to predict the CONUS ISP using the UNet model

    Args:
        tile_name (_type_):
        year (_type_):
        predictor (_type_): normalized predictor variables
        task_type_flag (_type_): regression or classification
        training_version (_type_): training version of UNet model
        epoch (_type_): epoch number
        output_folder_name (_type_): prediction output folder name: predict_isp_change or predict_is_mask
    """

    # the root folder of the trained U-Net model
    if rootpath_project_folder is None:
        rootpath_project_folder = rootpath_project
    dir_unet_training_folder = join(rootpath_project_folder, 'results', 'deep_learning', training_version)  # the root folder of the training model

    # load the training configuration
    with open(join(dir_unet_training_folder, 'model_training_output', '{}_config.yaml'.format(training_version))) as file_config:   # type: ignore
        config = yaml.full_load(file_config)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    # logger.info('device {}'.format(device))

    unet_model = unet_model_load(config=config, device=device, epoch=epoch, rootpath_save=dir_unet_training_folder)
    filename_unet_model = join(dir_unet_training_folder, 'model_training_output', 'model_output', f'unet_model_record_{epoch:02d}.pth')     # type: ignore
    logger.info(f'unet model load finished: {filename_unet_model}')

    print('predicting isp for tile {} year {}'.format(tile_name, year))
    logger.info('isp prediction for tile {} year {}'.format(tile_name, year))

    src_proj, src_geotrans = get_proj_info(tile_name)   # get the projection information

    if task_type_flag == 'classification':
        # classification task
        numpy_pred_mosaic = mosaic_prediction(predictor, device, unet_model, prediction_type='classification')

        numpy_pred_mosaic[np.isnan(numpy_pred_mosaic)] = 255
        output_filename = predict_isp_output(output_path, tile_name, year, numpy_pred_mosaic, src_geotrans, src_proj,
                                             filename_prefix=filename_prefix,
                                             gdal_type=gdalconst.GDT_Byte)

        add_pyramids_color_in_nlcd_isp_tif(output_filename)

        logger.info(f'IS mask prediction finished in {year} {tile_name}')
        logger.info(f'IS mask output file: {output_filename}')
    else:
        # regression task
        # predict the isp using the unet model
        numpy_pred_mosaic = mosaic_prediction(predictor, device, unet_model, prediction_type='regression')

        # cut off to [0, 100]
        numpy_pred_mosaic_cutoff = numpy_pred_mosaic.copy()
        numpy_pred_mosaic_cutoff[numpy_pred_mosaic_cutoff > 100] = 100
        numpy_pred_mosaic_cutoff[numpy_pred_mosaic_cutoff < 0] = 0

        # convert the float to uint8, NaN value is set as 255
        numpy_pred_mosaic_cutoff_round = np.round(numpy_pred_mosaic_cutoff)
        numpy_pred_mosaic_cutoff_round[np.isnan(numpy_pred_mosaic_cutoff_round)] = 255
        numpy_pred_mosaic_cutoff_round = numpy_pred_mosaic_cutoff_round.astype(np.uint8)

        # save the ISP prediction image
        output_filename = predict_isp_output(output_path, tile_name, year, numpy_pred_mosaic_cutoff_round,
                                             src_geotrans, src_proj,
                                             filename_prefix=filename_prefix,
                                             gdal_type=gdalconst.GDT_Byte)

        add_pyramids_color_in_nlcd_isp_tif(output_filename)

        logger.info(f'IS percentage prediction finished in {year} {tile_name}')
        logger.info(f'IS percentage output file: {output_filename}')

    return output_filename


def conus_mask_unet_is_pct_with_is_mask(output_filename_is_pct, output_filename_is_mask,
                                        tile_name, year,
                                        output_path, filename_prefix_mask_isp_output):

    img_predicted_isp = gdal_array.LoadFile(output_filename_is_pct)
    img_mask = gdal_array.LoadFile(output_filename_is_mask)

    img_predicted_isp_masked = img_predicted_isp * img_mask

    src_proj, src_geotrans = get_proj_info(tile_name)

    output_filename = predict_isp_output(output_path, tile_name, year, img_predicted_isp_masked,
                                         src_geotrans, src_proj,
                                         filename_prefix=filename_prefix_mask_isp_output,
                                         gdal_type=gdalconst.GDT_Byte)

    add_pyramids_color_in_nlcd_isp_tif(output_filename)

    return output_filename


@click.command()
@click.option('--rank', type=int, default=0, help='rank  $SLURM_ARRAY_TASK_ID, e.g., 1-32')
@click.option('--n_cores', type=int, default=1, help='the total applied cores   $SLURM_ARRAY_TASK_MAX')
def main(rank, n_cores):
# if __name__ == "__main__":
    # rank = 1
    # n_cores = 1

    list_year = np.arange(1988, 2021, 1)

    list_tile_name = get_conus_tile_name()
    list_tile_name.sort()

    with open(join(pwd, 'config_conus_isp_production.yaml')) as file:
        config = yaml.full_load(file)

    training_version_is_mask = config['training_version_is_mask']
    epoch_cls = config['epoch_cls']
    filename_prefix_is_mask = config['filename_prefix_is_mask']

    training_version_isp_regression = config['training_version_isp_regression']
    epoch_reg = config['epoch_reg']
    filename_prefix_is_pct = config['filename_prefix_is_pct']

    norm_boundary_folder = config['norm_boundary_folder']

    filename_prefix_mask_isp_output = config['filename_prefix_mask_isp_output']

    path_cold_reccg = config['path_cold_reccg']
    rootpath_product_output = config['rootpath_product_output']

    ##
    df_running_task = get_running_task(list_year, list_tile_name)

    ##
    each_core_block = int(np.ceil(len(df_running_task) / n_cores))
    for i in range(0, each_core_block):
        new_rank = rank - 1 + i * n_cores
        if new_rank > len(df_running_task) - 1:  # means that all folder has been processed
            print(f'{new_rank} this is the last running task')
        else:
            year = df_running_task.loc[new_rank, 'year']
            tile_name = df_running_task.loc[new_rank, 'tile_name']
            print(year, tile_name)

            # define the output folder
            output_path = join(rootpath_product_output, 'results', 'conus_isp', f'{year}', tile_name)
            if not os.path.exists(output_path):
                os.makedirs(output_path, exist_ok=True)

            # save the configuration file
            with open(join(output_path, f'{year}_{tile_name}_production_config.yaml'), 'w') as file:   # type: ignore
                yaml.dump(config, file)

            logger = define_logger(join(output_path, '{}_isp_production.log'.format(tile_name)))  # type: ignore

            logger.info(f'{year} {tile_name} start prediction')

            # prepare the predictor variables
            logger.info(f'{year} {tile_name} predictor variable preparation')

            predictor = pipeline_conus_predictor_preparation(path_cold_reccg=path_cold_reccg,
                                                             tile_name=tile_name,
                                                             year=year,
                                                             norm_boundary_folder=norm_boundary_folder,
                                                             logger=logger,
                                                             nan_fill=0,
                                                             rows_running=5000)

            logger.info(f'{year} {tile_name} predictor variable extraction finished')


            # predict the IS mask
            output_filename_is_mask = pipeline_conus_unet_prediction(tile_name=tile_name,
                                                                     year=year,
                                                                     predictor=predictor,
                                                                     output_path=output_path,
                                                                     task_type_flag='classification',
                                                                     logger=logger,
                                                                     training_version=training_version_is_mask,
                                                                     epoch=epoch_cls,
                                                                     filename_prefix=filename_prefix_is_mask,
                                                                     rootpath_project_folder=None,
                                                                     )

            # predict the IS percentage
            output_filename_is_pct = pipeline_conus_unet_prediction(tile_name=tile_name,
                                                                    year=year,
                                                                    predictor=predictor,
                                                                    output_path=output_path,
                                                                    task_type_flag='regression',
                                                                    logger=logger,
                                                                    training_version=training_version_isp_regression,
                                                                    epoch=epoch_reg,
                                                                    filename_prefix=filename_prefix_is_pct,
                                                                    rootpath_project_folder=None,
                                                                    )

            # mask the original regression ISP output with the binary classification mask
            output_filename = conus_mask_unet_is_pct_with_is_mask(output_filename_is_pct=output_filename_is_pct,
                                                                  output_filename_is_mask=output_filename_is_mask,
                                                                  tile_name=tile_name,
                                                                  year=year,
                                                                  output_path=output_path,
                                                                  filename_prefix_mask_isp_output=filename_prefix_mask_isp_output)

            logger.info(f'{year} {tile_name} mask IS percentage with IS mask finished')
            logger.info(f'{year} {tile_name} output file: {output_filename}')

            # write the finished flag
            f = open(join(output_path, f'{year}_{tile_name}_finished.txt'), 'w')    # type: ignore
            f.write(f'{year} {tile_name} ISP production running finished')
            f.close()

            logger.info(f'IS percentage prediction finished in {year} {tile_name}')


if __name__ == "__main__":
    main()